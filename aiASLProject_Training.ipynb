{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JValdez777/asl-translator-notebook/blob/main/aiASLProject_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras mediapipe-model-maker\n",
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "RXpgLSCDLc-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3704eac-9dee-453b-f0cc-170007a8402f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.11.0.86)\n",
            "Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-addons (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.9.8)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.16.1)\n",
            "Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.18.1)\n",
            "Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.10.0)\n",
            "Collecting numpy (from keras)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n",
            "Collecting ml-dtypes (from keras)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.9)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.2.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.168.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.15.2)\n",
            "Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.18.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.7.1)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.12.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.17.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.21.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9.1)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.1)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.70.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=96174bd5e6cbf5b48fcd9d0e9c617eb94c21904ee73af514e5e4a5a8c921739b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: wrapt, typeguard, tensorflow-estimator, protobuf, portalocker, numpy, keras, colorama, tensorflow-addons, sounddevice, sacrebleu, ml-dtypes, tensorflow-model-optimization, jaxlib, tensorboard, seqeval, jax, tensorflow, mediapipe, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.18.0\n",
            "    Uninstalling tf_keras-2.18.0:\n",
            "      Successfully uninstalled tf_keras-2.18.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.18.1\n",
            "    Uninstalling tensorflow-text-2.18.1:\n",
            "      Successfully uninstalled tensorflow-text-2.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.34 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.34 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 jax-0.4.34 jaxlib-0.4.34 keras-2.15.0 mediapipe-0.10.21 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 numpy-1.26.4 portalocker-3.1.1 protobuf-4.25.7 sacrebleu-2.5.1 seqeval-1.2.2 sounddevice-0.5.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jax",
                  "jaxlib",
                  "keras",
                  "ml_dtypes",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "69cf86c40bd848e2ae556e408e0e9487"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "JmDb4OdaD0fr",
        "outputId": "a9835bf7-c993-4ebd-de8e-f061c233f256"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow_addons'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5890a6c00918>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetrecursionlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Increase to a suitable value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "sys.setrecursionlimit(100000) # Increase to a suitable value\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from mediapipe.python.solutions.pose import Pose\n",
        "from mediapipe.python.solutions.pose import POSE_CONNECTIONS\n",
        "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Customizable Settings\n",
        "# ============================\n",
        "ASL_DIR = '/content/drive/MyDrive/ASL_Project/ASL_Alpha'\n",
        "MODEL_DIR = '/content/drive/MyDrive/ASL_Project/ASL_Model2'\n",
        "config_path = os.path.join(MODEL_DIR, 'model_config.json')\n",
        "delete_previous_model = False  # Option to delete previous model\n",
        "\n",
        "# Model parameters\n",
        "set_num_epochs = 200  # Lower; better generalization with early stopping\n",
        "set_batch_size = 16   # Smaller batches can help sequence models\n",
        "set_patience = 20\n",
        "set_patience_sensitivity = 0.0005\n",
        "set_min_lr = 1e-6\n",
        "set_factor = 0.5\n",
        "\n",
        "# Architecture parameters\n",
        "set_lstm_units = 128            # More capacity to learn from sequences\n",
        "set_dense_units = 64            # Better compression of LSTM output\n",
        "set_dropout_rate = 0.3          # Moderate regularization\n",
        "set_bidirectional = True\n",
        "set_learning_rate = 1e-4        # Keep this low for stability\n",
        "set_num_lstm_layers = 2         # More temporal abstraction\n",
        "set_num_dense_layers = 1\n",
        "set_activation = 'relu'\n",
        "set_regularizer_strength = 0.0001  # L2 regularization, reduced\n",
        "set_pose_noise_std = 0.01  # Add a tiny bit of pose jittering\n",
        "\n",
        "# Preprocessing parameters\n",
        "target_size = (64, 64)\n",
        "channels = 3"
      ],
      "metadata": {
        "id": "dfAFkqwxPRh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Initialization & Setup\n",
        "# ============================\n",
        "# Handle model directory\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "if delete_previous_model and os.path.exists(MODEL_DIR):\n",
        "    shutil.rmtree(MODEL_DIR)\n",
        "    os.makedirs(MODEL_DIR)\n",
        "\n",
        "# Function to extract pose keypoints from an image\n",
        "def extract_pose_keypoints(image, pose_model):\n",
        "    results = pose_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    if results.pose_landmarks:\n",
        "        keypoints = []\n",
        "        for lm in results.pose_landmarks.landmark:\n",
        "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
        "        return keypoints\n",
        "    else:\n",
        "        # Return all zeros if no pose is detected\n",
        "        return [0.0] * (33 * 4)\n",
        "\n",
        "# ============================\n",
        "# Calculate max_frames\n",
        "# ============================\n",
        "def calculate_max_frames(directory):\n",
        "    max_frames = 0\n",
        "    for sign in tqdm(os.listdir(directory), desc=\"Signs\"):\n",
        "        sign_dir = os.path.join(directory, sign)\n",
        "        if os.path.isdir(sign_dir):\n",
        "            for video in os.listdir(sign_dir):\n",
        "                video_path = os.path.join(sign_dir, video)\n",
        "                if os.path.isdir(video_path):\n",
        "                    try:\n",
        "                        frame_count = len([f for f in os.listdir(video_path) if f.endswith('.jpg')])\n",
        "                        if frame_count > max_frames:\n",
        "                            max_frames = frame_count\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error accessing {video_path}: {e}\")\n",
        "    return max_frames\n",
        "\n",
        "max_frames = calculate_max_frames(ASL_DIR)\n",
        "print(f\"Calculated maximum frames across all videos: {max_frames}\")\n",
        "\n",
        "# ============================\n",
        "# Data Augmentation for Pose Data\n",
        "# ============================\n",
        "def augment_pose_sequence(pose_data, noise_std=set_pose_noise_std):\n",
        "    \"\"\"Augment pose sequence data by adding noise and transformations.\"\"\"\n",
        "    augmented_pose = pose_data.copy()\n",
        "\n",
        "    # Adding noise to pose data (random jitter)\n",
        "    noise = np.random.normal(0, noise_std, augmented_pose.shape)\n",
        "    augmented_pose += noise\n",
        "\n",
        "    # Optionally, add more augmentations like scaling, flipping, or rotating here if needed\n",
        "\n",
        "    return augmented_pose\n",
        "\n",
        "def augment_video_pose(video_dir, augmentations_needed=1):\n",
        "    \"\"\"Create augmented copies of a video by applying random transformations.\"\"\"\n",
        "    pose_file = os.path.join(video_dir, 'processed_poses.npy')\n",
        "    if not os.path.exists(pose_file):\n",
        "        print(f\"Pose data not found for {video_dir}\")\n",
        "        return []\n",
        "\n",
        "    pose_data = np.load(pose_file)\n",
        "    augmented_dirs = []\n",
        "\n",
        "    parent_dir = os.path.dirname(video_dir)\n",
        "    base_name = os.path.basename(video_dir)\n",
        "\n",
        "    augmented_index = 0\n",
        "    for _ in range(augmentations_needed):\n",
        "        new_video_name = f'augmentedposes_{augmented_index}'\n",
        "        new_video_path = os.path.join(parent_dir, new_video_name)\n",
        "        os.makedirs(new_video_path, exist_ok=True)\n",
        "\n",
        "        augmented_pose_data = augment_pose_sequence(pose_data)\n",
        "        np.save(os.path.join(new_video_path, 'processed_poses.npy'), augmented_pose_data)\n",
        "\n",
        "        augmented_dirs.append(new_video_path)\n",
        "        augmented_index += 1\n",
        "\n",
        "    return augmented_dirs\n",
        "\n",
        "# ============================\n",
        "# Preprocessing Generator for Pose Data\n",
        "# ============================\n",
        "class PoseDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, video_paths, labels, label_to_index, batch_size):\n",
        "        self.video_paths = video_paths\n",
        "        self.labels = labels\n",
        "        self.label_to_index = label_to_index\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(len(self.video_paths))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.video_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_videos = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            video_dir = self.video_paths[i]\n",
        "            processed_path = os.path.join(video_dir, 'pose.npy')\n",
        "\n",
        "            if not os.path.exists(processed_path):\n",
        "                print(f\"Skipping: {processed_path} not found\")\n",
        "                continue\n",
        "\n",
        "            video_data = np.load(processed_path)\n",
        "\n",
        "            # Pad/truncate to max_frames\n",
        "            if video_data.shape[0] < max_frames:\n",
        "                pad_width = max_frames - video_data.shape[0]\n",
        "                video_data = np.pad(video_data, ((0, pad_width), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                video_data = video_data[:max_frames]\n",
        "\n",
        "            batch_videos.append(video_data)\n",
        "            batch_labels.append(self.label_to_index[self.labels[i]])\n",
        "\n",
        "        if not batch_videos:  # Skip if no valid data\n",
        "            return np.zeros((0, max_frames, video_data.shape[1])), np.zeros((0,))\n",
        "\n",
        "        return np.array(batch_videos), np.array(batch_labels)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "# ============================\n",
        "# Collect all video paths and labels\n",
        "# ============================\n",
        "video_paths = []\n",
        "labels = []\n",
        "for sign in tqdm(os.listdir(ASL_DIR), desc=\"Signs\"):\n",
        "    sign_dir = os.path.join(ASL_DIR, sign)\n",
        "    if os.path.isdir(sign_dir):\n",
        "        videos = [v for v in os.listdir(sign_dir) if os.path.isdir(os.path.join(sign_dir, v))]\n",
        "\n",
        "        # Handle signs with only 1 video\n",
        "        if len(videos) == 1:\n",
        "            video_path = os.path.join(sign_dir, videos[0])\n",
        "            print(f\"Augmenting single video for sign: {sign}\")\n",
        "            augmented_dirs = augment_video_pose(video_path, augmentations_needed=10)\n",
        "            videos += [os.path.basename(d) for d in augmented_dirs]\n",
        "\n",
        "        # Add all videos (original + augmented) to dataset\n",
        "        for video in videos:\n",
        "            video_paths.append(os.path.join(sign_dir, video))\n",
        "            labels.append(sign)\n",
        "\n",
        "# Create label mapping\n",
        "label_to_index = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
        "num_classes = len(label_to_index)\n",
        "\n",
        "print(f\"Total signs: {num_classes}\")\n",
        "print(f\"Total video samples: {len(video_paths)}\")\n",
        "\n",
        "# Split data with stratification\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    video_paths, labels, test_size=0.2, stratify=labels)\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    train_paths, train_labels, test_size=0.2, stratify=train_labels)\n",
        "\n",
        "# Create generators\n",
        "train_gen = PoseDataGenerator(train_paths, train_labels, label_to_index, set_batch_size)\n",
        "val_gen = PoseDataGenerator(val_paths, val_labels, label_to_index, set_batch_size)\n",
        "\n",
        "# ============================\n",
        "# Model Architecture\n",
        "# ============================\n",
        "def build_model(num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # First LSTM layer needs input shape\n",
        "    if set_bidirectional:\n",
        "        model.add(layers.Bidirectional(layers.LSTM(set_lstm_units, return_sequences=True),\n",
        "                                       input_shape=(max_frames, 132)))\n",
        "    else:\n",
        "        model.add(layers.LSTM(set_lstm_units, return_sequences=True, input_shape=(max_frames, 132)))\n",
        "\n",
        "    for _ in range(set_num_lstm_layers - 1):\n",
        "        if set_bidirectional:\n",
        "            model.add(layers.Bidirectional(layers.LSTM(set_lstm_units, return_sequences=True)))\n",
        "        else:\n",
        "            model.add(layers.LSTM(set_lstm_units, return_sequences=True))\n",
        "\n",
        "    model.add(layers.LSTM(set_lstm_units))\n",
        "\n",
        "    for _ in range(set_num_dense_layers):\n",
        "        model.add(layers.Dense(set_dense_units, activation=set_activation))\n",
        "        model.add(layers.Dropout(set_dropout_rate))\n",
        "\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    optimizer = optimizers.Adam(learning_rate=set_learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxLwg-gqLZm3",
        "outputId": "6c25cc4b-4a2a-4d79-f15a-2d81f1554d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Signs: 100%|██████████| 26/26 [00:00<00:00, 67.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated maximum frames across all videos: 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Signs: 100%|██████████| 26/26 [00:00<00:00, 407.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total signs: 26\n",
            "Total video samples: 286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through the dataset structure\n",
        "with Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
        "    for word in sorted(os.listdir(ASL_DIR)):\n",
        "        word_path = os.path.join(ASL_DIR, word)\n",
        "        if not os.path.isdir(word_path):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing: {word}\")\n",
        "        for sequence_folder in tqdm(sorted(os.listdir(word_path))):\n",
        "            seq_path = os.path.join(word_path, sequence_folder)\n",
        "            if not os.path.isdir(seq_path):\n",
        "                continue\n",
        "\n",
        "            # Skip if pose.npy already exists\n",
        "            out_path = os.path.join(seq_path, 'pose.npy')\n",
        "            if os.path.exists(out_path):\n",
        "                continue\n",
        "\n",
        "            frames = sorted([f for f in os.listdir(seq_path) if f.endswith('.jpg')])\n",
        "            if not frames:\n",
        "                print(f\"Warning: No frames in {seq_path}\")\n",
        "                continue\n",
        "\n",
        "            pose_sequence = []\n",
        "            for frame_name in frames:\n",
        "                frame_path = os.path.join(seq_path, frame_name)\n",
        "                image = cv2.imread(frame_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "                keypoints = extract_pose_keypoints(image, pose)\n",
        "                pose_sequence.append(keypoints)\n",
        "\n",
        "            pose_sequence = np.array(pose_sequence)\n",
        "            np.save(out_path, pose_sequence)\n",
        "\n",
        "# ============================\n",
        "# Callbacks & Training\n",
        "# ============================\n",
        "callbacks = [\n",
        "    callbacks.EarlyStopping(monitor='val_loss', patience=set_patience,\n",
        "                          min_delta=set_patience_sensitivity, restore_best_weights=True),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=set_factor,\n",
        "                              patience=set_patience//2, min_lr=set_min_lr),\n",
        "    callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, 'best_model.keras'),\n",
        "                            save_best_only=False)\n",
        "]\n",
        "\n",
        "model_path = os.path.join(MODEL_DIR, 'final_model.keras')\n",
        "if os.path.exists(model_path):\n",
        "    print(\"Loading existing model...\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "else:\n",
        "    print(\"Building new model...\")\n",
        "    model = build_model(num_classes)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=set_num_epochs,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Save Final Model\n",
        "# ============================\n",
        "model.save(os.path.join(MODEL_DIR, 'final_model.h5', ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo0jrte4Nd7l",
        "outputId": "946a0679-b727-408c-aae7-c9c3aa02ed40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1537.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1636.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2060.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2107.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: E\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1779.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: F\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 3304.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1943.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 3210.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2982.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: J\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2894.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: K\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 880.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2666.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1239.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: N\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1586.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1018.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: P\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1407.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1830.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: R\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1900.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 2044.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1360.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: U\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1577.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: V\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1427.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: W\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1455.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: X\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1915.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: Y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1310.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: Z\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1101.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing model...\n",
            "Epoch 1/200\n",
            "12/12 [==============================] - 17s 659ms/step - loss: 0.7851 - accuracy: 0.7967 - val_loss: 0.4356 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 2/200\n",
            "12/12 [==============================] - 4s 311ms/step - loss: 0.8134 - accuracy: 0.7473 - val_loss: 0.4268 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 3/200\n",
            "12/12 [==============================] - 5s 449ms/step - loss: 0.7268 - accuracy: 0.8022 - val_loss: 0.4252 - val_accuracy: 0.9348 - lr: 2.5000e-05\n",
            "Epoch 4/200\n",
            "12/12 [==============================] - 5s 427ms/step - loss: 0.7013 - accuracy: 0.8077 - val_loss: 0.4161 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - 5s 427ms/step - loss: 0.6226 - accuracy: 0.8571 - val_loss: 0.4218 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 6/200\n",
            "12/12 [==============================] - 5s 406ms/step - loss: 0.5986 - accuracy: 0.8626 - val_loss: 0.4221 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 7/200\n",
            "12/12 [==============================] - 4s 310ms/step - loss: 0.6023 - accuracy: 0.8352 - val_loss: 0.4460 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 8/200\n",
            "12/12 [==============================] - 4s 333ms/step - loss: 0.5710 - accuracy: 0.8571 - val_loss: 0.4302 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 9/200\n",
            "12/12 [==============================] - 4s 351ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.4368 - val_accuracy: 0.9348 - lr: 2.5000e-05\n",
            "Epoch 10/200\n",
            "12/12 [==============================] - 4s 311ms/step - loss: 0.5463 - accuracy: 0.8846 - val_loss: 0.4417 - val_accuracy: 0.9348 - lr: 2.5000e-05\n",
            "Epoch 11/200\n",
            "12/12 [==============================] - 4s 339ms/step - loss: 0.6124 - accuracy: 0.8462 - val_loss: 0.4422 - val_accuracy: 0.9130 - lr: 2.5000e-05\n",
            "Epoch 12/200\n",
            "12/12 [==============================] - 5s 376ms/step - loss: 0.5492 - accuracy: 0.8516 - val_loss: 0.4447 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 13/200\n",
            "12/12 [==============================] - 4s 309ms/step - loss: 0.6108 - accuracy: 0.8462 - val_loss: 0.4363 - val_accuracy: 0.9130 - lr: 2.5000e-05\n",
            "Epoch 14/200\n",
            "12/12 [==============================] - 4s 349ms/step - loss: 0.5491 - accuracy: 0.8571 - val_loss: 0.4627 - val_accuracy: 0.9565 - lr: 2.5000e-05\n",
            "Epoch 15/200\n",
            "12/12 [==============================] - 4s 341ms/step - loss: 0.5597 - accuracy: 0.8462 - val_loss: 0.4416 - val_accuracy: 0.9565 - lr: 1.2500e-05\n",
            "Epoch 16/200\n",
            "12/12 [==============================] - 4s 309ms/step - loss: 0.5523 - accuracy: 0.8901 - val_loss: 0.4572 - val_accuracy: 0.9130 - lr: 1.2500e-05\n",
            "Epoch 17/200\n",
            "12/12 [==============================] - 4s 335ms/step - loss: 0.5215 - accuracy: 0.8681 - val_loss: 0.4400 - val_accuracy: 0.9348 - lr: 1.2500e-05\n",
            "Epoch 18/200\n",
            "12/12 [==============================] - 5s 415ms/step - loss: 0.5890 - accuracy: 0.8187 - val_loss: 0.4457 - val_accuracy: 0.9348 - lr: 1.2500e-05\n",
            "Epoch 19/200\n",
            "12/12 [==============================] - 4s 312ms/step - loss: 0.4622 - accuracy: 0.9011 - val_loss: 0.4449 - val_accuracy: 0.9565 - lr: 1.2500e-05\n",
            "Epoch 20/200\n",
            "12/12 [==============================] - 4s 310ms/step - loss: 0.5135 - accuracy: 0.9066 - val_loss: 0.4425 - val_accuracy: 0.9565 - lr: 1.2500e-05\n",
            "Epoch 21/200\n",
            "12/12 [==============================] - 6s 502ms/step - loss: 0.4820 - accuracy: 0.8571 - val_loss: 0.4335 - val_accuracy: 0.9130 - lr: 1.2500e-05\n",
            "Epoch 22/200\n",
            "12/12 [==============================] - 4s 344ms/step - loss: 0.4923 - accuracy: 0.8846 - val_loss: 0.4361 - val_accuracy: 0.9565 - lr: 1.2500e-05\n",
            "Epoch 23/200\n",
            "12/12 [==============================] - 4s 310ms/step - loss: 0.5319 - accuracy: 0.8791 - val_loss: 0.4426 - val_accuracy: 0.9348 - lr: 1.2500e-05\n",
            "Epoch 24/200\n",
            "12/12 [==============================] - 5s 412ms/step - loss: 0.4937 - accuracy: 0.8791 - val_loss: 0.4438 - val_accuracy: 0.9348 - lr: 1.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below is misc. and should not be run normally**"
      ],
      "metadata": {
        "id": "y4Ww8CIkmb-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Save Model in HDF5 Format (without time_major issue)\n",
        "# ============================\n",
        "model_save_path = os.path.join(MODEL_DIR, 'best_model_fixed.h5')\n",
        "\n",
        "# Remove conflicting time_major attribute before saving\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.LSTM):\n",
        "        layer.time_major = False  # Explicitly set time_major to False to prevent issues\n",
        "\n",
        "# Save the model\n",
        "model.save('best_model_fixed.h5', include_optimizer=False)\n",
        "\n",
        "print(f\"Model successfully saved in HDF5 format: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZDJh_g6mC0m",
        "outputId": "58537283-eb5a-47a5-f9fa-0ed31c58f785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved in HDF5 format: /content/drive/MyDrive/ASL_Project/ASL_Model2/best_model_fixed.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================\n",
        "# Data Augmentation\n",
        "# ================\n",
        "def augment_video(video_dir, augmentations_needed=1):\n",
        "    \"\"\"Create augmented copies of a video by applying random transformations\"\"\"\n",
        "    frame_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.jpg')])\n",
        "    if not frame_files:\n",
        "        return []\n",
        "\n",
        "    parent_dir = os.path.dirname(video_dir)\n",
        "    base_name = os.path.basename(video_dir)\n",
        "    existing_video_dirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]\n",
        "\n",
        "    # Start numbering augmented videos\n",
        "    augmented_index = 0\n",
        "\n",
        "    augmented_dirs = []\n",
        "    for i in range(augmentations_needed):\n",
        "        new_video_name = f'augmented_{augmented_index}'\n",
        "        new_video_path = os.path.join(parent_dir, new_video_name)\n",
        "        os.makedirs(new_video_path, exist_ok=True)\n",
        "\n",
        "        for frame_file in frame_files:\n",
        "            img = tf.io.read_file(os.path.join(video_dir, frame_file))\n",
        "            img = tf.image.decode_jpeg(img, channels=channels)\n",
        "\n",
        "            # Apply random augmentations\n",
        "            img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "            img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
        "            img = tf.image.random_hue(img, max_delta=0.1)\n",
        "            img = tf.image.random_saturation(img, lower=0.8, upper=1.2)\n",
        "\n",
        "            # Add slight rotation\n",
        "            angle = tf.random.uniform([], -0.1, 0.1)\n",
        "            img = tfa.image.rotate(img, angle)\n",
        "\n",
        "            frame_num = frame_file.split('_')[1].split('.')[0]\n",
        "            tf.io.write_file(\n",
        "                os.path.join(new_video_path, f'frame_{frame_num}.jpg'),\n",
        "                tf.image.encode_jpeg(tf.cast(img * 255, tf.uint8)))\n",
        "\n",
        "        augmented_dirs.append(new_video_path)\n",
        "        augmented_index += 1\n",
        "\n",
        "    return augmented_dirs\n",
        "\n",
        "# Collect all video paths and labels\n",
        "video_paths = []\n",
        "labels = []\n",
        "for sign in tqdm(os.listdir(ASL_DIR), desc=\"Signs\"):\n",
        "    sign_dir = os.path.join(ASL_DIR, sign)\n",
        "    if os.path.isdir(sign_dir):\n",
        "        videos = [v for v in os.listdir(sign_dir) if os.path.isdir(os.path.join(sign_dir, v))]\n",
        "\n",
        "        # Handle signs with only 1 video\n",
        "        if len(videos) == 1:\n",
        "            video_path = os.path.join(sign_dir, videos[0])\n",
        "            print(f\"Augmenting single video for sign: {sign}\")\n",
        "            augmented_dirs = augment_video(video_path, augmentations_needed=10)\n",
        "            videos += [os.path.basename(d) for d in augmented_dirs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3WAFzJyRI7L",
        "outputId": "93a38d3d-fee4-4878-fbaf-bf56b1ff3404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Signs: 100%|██████████| 26/26 [00:00<00:00, 393.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root = '/content/drive/MyDrive/ASL_Project/ASL_Alpha'\n",
        "for word in os.listdir(root):\n",
        "    word_path = os.path.join(root, word)\n",
        "    if not os.path.isdir(word_path): continue\n",
        "    for video in os.listdir(word_path):\n",
        "        video_path = os.path.join(word_path, video)\n",
        "        if not os.path.isdir(video_path): continue\n",
        "        src = os.path.join(video_path, 'processed.npy')\n",
        "        dst = os.path.join(video_path, 'processed_poses.npy')\n",
        "        if os.path.exists(src) and not os.path.exists(dst):\n",
        "            os.rename(src, dst)"
      ],
      "metadata": {
        "id": "K_e6v2OblJuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKmZUremABrn",
        "outputId": "3b526eb7-0263-423f-d18e-13bb5d2326f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QE_7-WWTF1UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ijTVTF4GCLR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}