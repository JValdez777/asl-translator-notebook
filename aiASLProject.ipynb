{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1FZHBbat18p6w7wbytv2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JValdez777/asl-translator-notebook/blob/main/aiASLProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing needed libraries"
      ],
      "metadata": {
        "id": "kA5IV3zOriES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "at2sk81h56wl"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade mediapipe==0.10.21\n",
        "!pip install --quiet opencv-python torch torchvision numpy matplotlib\n",
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprint 1: setup webcam functionality and mediapipe hands.\n",
        "Goals:\n",
        "Understand MediaPipe API calls."
      ],
      "metadata": {
        "id": "0IGHvIQw8MG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For mounting onto drive and importing pretrained ai model."
      ],
      "metadata": {
        "id": "heESip4GrbNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# For now, comment out loading weightsâ€”use a stub\n",
        "# model.load_state_dict(torch.load(...))\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oigT54Nb8XOO",
        "outputId": "b7346b02-40fe-47fa-b2e7-374e3bbc4855"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if everything imported and is working properly"
      ],
      "metadata": {
        "id": "6KzeddLqrnf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import torch\n",
        "\n",
        "# Check that the 'solutions' namespace is present\n",
        "print(\"Has solutions module?\", hasattr(mp, \"solutions\"))\n",
        "\n",
        "# Now check inside solutions for the hands API\n",
        "print(\"Has hands in solutions?\", hasattr(mp.solutions, \"hands\"))\n",
        "\n",
        "print(\"OpenCV:\", cv2.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_SDp1kb82pf",
        "outputId": "aa80206c-5741-407a-f30c-37fc8f9f45b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Has solutions module? True\n",
            "Has hands in solutions? True\n",
            "OpenCV: 4.11.0\n",
            "Torch: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python for setting up mediapipe and encoding a jpeg into a numpy array for processing within js script.\n"
      ],
      "metadata": {
        "id": "08JUcQdurs7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#setting up mediapipe hands | making a max of two hand objects then setting detection confidence\n",
        "mp_hands = mp.solutions.hands.Hands(\n",
        "    max_num_hands=2,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5,\n",
        ")\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "def process_frame(data_url):\n",
        "  #prevents stacking of multiple frames\n",
        "  clear_output(wait=True)\n",
        "  #decode base64 jpeg into numpy array\n",
        "  header, encoded = data_url.split(',',1)\n",
        "  frame_bytes = base64.b64decode(encoded)\n",
        "  arr = np.frombuffer(frame_bytes, dtype=np.uint8)\n",
        "  frame = cv2.imdecode(arr, flags=cv2.IMREAD_COLOR)\n",
        "\n",
        "  #running media pipe hand detection\n",
        "  rgb_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "  results = mp_hands.process(rgb_frame)\n",
        "\n",
        "  #drawing hand landmarks\n",
        "  if results.multi_hand_landmarks:\n",
        "    for hand_landmarks in results.multi_hand_landmarks:\n",
        "      mp_draw.draw_landmarks(\n",
        "          frame,\n",
        "          hand_landmarks,\n",
        "          mp.solutions.hands.HAND_CONNECTIONS\n",
        "      )\n",
        "\n",
        "    #stub asl prediction ai model wil be used here\n",
        "    pred = \"A\"\n",
        "    cv2.putText(\n",
        "        frame, pred,\n",
        "        org=(10,30),\n",
        "        fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=1,\n",
        "        color=(0,255,0),\n",
        "        thickness=2\n",
        "    )\n",
        "\n",
        "    #showing annoted frame inline from output\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "  #register this function so JS can call it by name\n",
        "output.register_callback('notebook.process_frame',process_frame)\n",
        "\n",
        "print(\"process_frame callback registered\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vGBDw7fKq1hL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba90628-98fd-452e-f87e-7f23ad75de5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process_frame callback registered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- 1. Creating and displaying a video element within the notebook-->\n",
        "<!-- 2. invoking a async funciton to\n",
        "  a) ask browser for webcam access\n",
        "  b) send frames to python-->\n",
        "<!-- 2a) Getting video element we set up in step 1-->\n",
        "<!-- 2b) Asking user for webcam permissions and getting the live stream-->\n",
        "\n",
        "<!-- 3. Setting up timer interval so that every 100 ms:\n",
        "  a) Draws the current video frame onto an off-screen canvas\n",
        "  b) encodes this canvas as a jpeg data-url (Base64 string)\n",
        "  c) send this back to python using colab's callback api-->\n",
        "\n",
        "<!-- error handling for camera\n",
        "  if the camera fails log error and alert-->"
      ],
      "metadata": {
        "id": "DgM6pYXC0wCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Creating and displaying a video element within the notebook\n",
        " 2. invoking a async funciton to\n",
        "  a) ask browser for webcam access\n",
        "  b) send frames to python\n",
        "2a) Getting video element we set up in step 1\n",
        "2b) Asking user for webcam permissions and getting the live stream\n",
        "\n",
        " 3. Setting up timer interval so that every 100 ms:\n",
        "  a) Draws the current video frame onto an off-screen canvas\n",
        "  b) encodes this canvas as a jpeg data-url (Base64 string)\n",
        "  c) send this back to python using colab's callback api\n",
        "\n",
        "error handling for camera\n",
        "  if the camera fails log error and alert"
      ],
      "metadata": {
        "id": "uiMczcjt0yIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RzFMkCB9WRyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!-- 1. Creating and displaying a video element within the notebook-->\n",
        "<video id=\"cam\" width=\"640\" height=\"480\" autoplay playsinline></video>\n",
        "<!-- 2. invoking a async funciton to\n",
        "  a) ask browser for webcam access\n",
        "  b) send frames to python-->\n",
        "<script>\n",
        "(async function(){\n",
        "  const video = document.getElementById('cam');\n",
        "  try{\n",
        "    //asking for webcam access\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "    video.srcObject = stream;\n",
        "\n",
        "    //every 100 ms grabe a frame to send to python\n",
        "    setInterval(() => {\n",
        "      //draw video onto off-screen canvas\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video,0,0);\n",
        "\n",
        "      //converts canvas to jpeg data url\n",
        "      const dataUrl = canvas.toDataURL('image/jpeg');\n",
        "\n",
        "      //invoke python callback with string (data url)\n",
        "      google.colab.kernel.invokeFunction(\n",
        "        'notebook.process_frame',\n",
        "        [dataUrl],\n",
        "        {}\n",
        "      );\n",
        "    }, 100);\n",
        "  }\n",
        "  catch(err){\n",
        "    console.error('Camera error:', err);\n",
        "    alert('Could not access camera: ' + err.message);\n",
        "  }\n",
        "})();\n",
        "</script>\n"
      ],
      "metadata": {
        "id": "ZzkQ6E8AACkl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}